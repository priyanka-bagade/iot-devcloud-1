{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intruder Detector Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"warn\"><h2>Important: Before proceeding, please run the following cell to check for updates to this and other samples.</h2></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qarpo.catalog import DemoCatalog\n",
    "import os\n",
    "status = DemoCatalog(os.getcwd(), \"Demo\").ShowRepositoryControls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This application is one of a series of IoT reference implementations illustrating how to develop a working solution for a problem. The reference implementation demonstrates how to create a smart video IoT solution using Intel® hardware and software tools. This solution detects any number of objects in a designated area, providing the number of objects in the frame and total count.\n",
    "\n",
    "## Overview of how it works\n",
    "At start-up the sample application reads the equivalent of command line arguments and loads a network and image from the video input to the Inference Engine (IE) plugin. A job is submitted to an edge compute node with a hardware accelerator such as Intel® HD Graphics GPU, Intel® Movidius™ Neural Compute Stick 2 and and Intel® Arria® 10 FPGA.\n",
    "After the inference is completed, the output videos are appropriately stored in the /results/[device] directory, which can then be viewed within the Jupyter Notebook instance.\n",
    "\n",
    "## Demonstration objectives\n",
    "* Video as input is supported using **OpenCV**\n",
    "* Inference performed on edge hardware (rather than on the development node hosting this Jupyter notebook)\n",
    "* **OpenCV** provides the bounding boxes, labels and other information\n",
    "* Visualization of the resulting bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "<br><div class=danger><b>TODO</b></div>\n",
    "\n",
    "### The Labels File\n",
    "\n",
    "In order to work, this application requires a labels file associated with the model being used for detection.\n",
    "\n",
    "The labels file is a text file containing all the classes/labels that the model can recognize, in the order that it was trained to recognize them (one class per line).\n",
    "\n",
    "For the **person-vehicle-bike-detection-crossroad-0078** model, find the class file labels.txt in the resources folder.\n",
    "\n",
    "### The Config File\n",
    "\n",
    "The resources/conf.txt contains the path to the video that will be used by the application, followed by the labels to be detected on video. All labels (intruders) defined will be detected on video.\n",
    "\n",
    "Each line of the conf.txt file is of the form ``video: <path/to/video>`` or ``intruder: <label>``.<br>\n",
    "The labels used in the conf.txt file must coincide with the labels from the labels file.\n",
    "\n",
    "Example of the conf.txt file:\n",
    "\n",
    "```\n",
    "video: videos/video1.mp4\n",
    "intruder: person\n",
    "intruder: dog\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Intel® Distribution of OpenVINO™ toolkit\n",
    "\n",
    "We will be using Intel® Distribution of OpenVINO™ toolkit Inference Engine (IE) to locate intruder in the frame.\n",
    "There are five steps involved in this task:\n",
    "\n",
    "1. Create an Intermediate Representation (IR) Model using the Model Optimizer by Intel\n",
    "2. Choose a device and create IEPlugin for the device\n",
    "3. Read the IRModel using IENetwork\n",
    "4. Load the IENetwork into the Plugin\n",
    "5. Run inference.\n",
    "\n",
    "### Creating IR Model\n",
    "\n",
    "The Model Optimizer creates Intermediate Representation (IR) models that are optimized for different end-point target devices.\n",
    "These models can be created from existing DNN models from popular frameworks (e.g. Caffe*, TF) using the Model Optimizer. \n",
    "The Intel® Distribution of OpenVINO™ toolkit includes a utility script `model_downloader.py` that you can use to download some common models. Run the following cell to see the models available through `model_downloader.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The '!' is a special Jupyter Notebook command that allows you to run shell commands as if you are in a command line. So the above command will work straight out of the box on in a terminal (with '!' removed).\n",
    "\n",
    "Some of these downloaded models are already in the IR format, while others will require the model optimizer. In this demo, we will be using the **person-vehicle-bike-detection-crossroad-0078** model, which is already in IR format. This model can be downloaded with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name person-vehicle-bike-detection-crossroad-0078 -o models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments are as follows:\n",
    "* --name : name of the model you want to download. It should be one of the models listed in the previous cell\n",
    "* -o : output directory. If this directory does not exist, it will be created for you.\n",
    "\n",
    "There are more arguments to this script and you can get the full list using the `-h` option.\n",
    "\n",
    "\n",
    "With the `-o` option set as above, this command downloads the model in the directory `models`, with the model files (.xml and .bin) located at `/Security/object_detection/crossroad/0078/dldt directory`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Demo\n",
    "<br><div class=danger><b>TODO</b></div>\n",
    "Submit the job using `qarpo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qarpo\n",
    "import json\n",
    "\n",
    "with open('job_config.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_interface = qarpo.Interface(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_interface.displayUI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
