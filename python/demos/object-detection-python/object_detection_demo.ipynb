{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='red'>  Important: </font> Before proceeding, run the following cell to check for code updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qarpo.catalog import DemoCatalog\n",
    "import os\n",
    "status = DemoCatalog(os.getcwd(), \"Demo\").ShowRepositoryControls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo: Car Detection\n",
    "\n",
    "This is a sample reference implementation to showcase object detection (car in this case) with single-shot detection (SSD) and Async API.\n",
    "Async API improves the overall frame-rate of the application by not waiting for the inference to complete but continuing to do things on the host while inference accelerator is busy. \n",
    "Specifically, this code demonstrates two parallel inference requests by processing the current frame while the next input frame is being captured. This essentially hides the latency of frame capture.\n",
    "\n",
    "## Overview of how it works\n",
    "At start-up the sample application reads the equivalent of command line arguments and loads a network and image from the video input to the Inference Engine (IE) plugin. \n",
    "A job is submitted to a hardware accelerator (Intel® Core CPU, Intel® HD Graphics GPU, Intel® Core CPU, Intel® Neural Compute Stick 2, Intel® Movidius™ Vision Processing Unit (8x VPU), and Intel® Arria® 10 FPGA.\n",
    "After the inference is completed, the output videos are appropriately stored in the /results directory, which can then be viewed within the Jupyter Notebook instance. \n",
    "\n",
    "## Demonstration objectives\n",
    "* Video as input is supported using **OpenCV**\n",
    "* Inference performed on edge hardware (rather than on the development node hosting this Jupyter notebook)\n",
    "* **OpenCV** provides the bounding boxes, labels and other information\n",
    "* Visualization of the resulting bounding boxes\n",
    "* Demonstrate the Async API in action\n",
    "\n",
    "## How do I modify the above demonstration objectives?\n",
    "Modify the job_config.json file accompanying this example, this file is located in the same directory\n",
    "It is possible to change the raw model used, change the precision of the IR files, or input video and target configurations as desired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Intermediate Representation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Optimizer creates the Intermediate Representation of the model which is the device-agnostic, generic optimization of the model. Caffe\\*, TensorFlow\\*, MXNet\\*, ONNX\\*, and Kaldi\\* models are supported by Model Optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **MobileNet-SSD** model for this example. Download the model, specifying the name and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o raw_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this model to the intermediate representation using Model Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--data_type FP32 \\\n",
    "--output_dir models/mobilenet-ssd/FP32 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] \\\n",
    "--silent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the FP16 IR version of the model for the calculations on Neural Compute Stick 2 (NCS2) and Visual Processing Unit (VPU); let's create it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
    "--input_model raw_models/public/mobilenet-ssd/mobilenet-ssd.caffemodel \\\n",
    "--data_type FP16 \\\n",
    "--output_dir models/mobilenet-ssd/FP16 \\\n",
    "--scale 256 \\\n",
    "--mean_values [127,127,127] \\\n",
    "--silent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and configuration file for widget management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qarpo\n",
    "import json\n",
    "with open('job_config.json') as json_file:  \n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display available options for Intel® Edge compute hardware and acceleration, results and performance summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_interface = qarpo.Interface(data).displayUI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
